<!--Arquitectura u4
Autor: Lilian Ramos-->
<html>
<head>
	<title>UNIDAD 4</title>
	<meta charset = "UTF-8">
	<link rel="stylesheet" type="text/css" media="screen" href="Style.css">
	<link rel="preconnect" href="https://fonts.googleapis.com">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link href="https://fonts.googleapis.com/css2?family=Rubik+Glitch&display=swap" rel="stylesheet">
</head>
<body>
<body class="FondoU2">
	<h1 class="fontU" align="center">Procesamiento paralelo</h1>
	<img src="PL.jpeg" width="500" height="300" align="center">
	<div  class="bloqueU4">
		<p align="center">4.1 Aspectos básicos de la computación</p>
		<p align="left">La computación paralela es una forma de cómputo en la que muchas instrucciones se ejecutan simultáneamente, operando sobre el principio de que problemas grandes, a menudo se pueden dividir en unos más pequeños, que luego son resueltos simultáneamente (en paralelo). Hay varias formas diferentes de computación paralela: 
		paralelismo a nivel de bit, paralelismo a nivel de instrucción, paralelismo de datos y paralelismo de tareas. El paralelismo se ha empleado durante muchos años, sobre todo en la computación de altas prestaciones, pero el interés en ella ha crecido últimamente debido a las limitaciones físicas que impiden el aumento de la frecuencia. 
		Como el consumo de energía y por consiguiente la generación de calor de las computadoras constituye una preocupación en los últimos años, la computación en paralelo se ha convertido en el paradigma dominante en la arquitectura de computadores, principalmente en forma de procesadores multinúcleo.
		</p>
		<p align="center">4.2 Tipos de computación</p>
		<p align="left">
		Paralelismo a nivel de bit.
		Desde el advenimiento de la integración a gran escala (VLSI) como tecnología de fabricación de chips de computadora en la década de 1970 hasta alrededor de 1986, la aceleración en la arquitectura de computadores se lograba en gran medida duplicando el tamaño de la palabra en la computadora, la cantidad de información que el procesador puede manejar por ciclo. 
		El aumento del tamaño de la palabra reduce el número de instrucciones que el procesador debe ejecutar para realizar una operación en variables cuyos tamaños son mayores que la longitud de la palabra. Por ejemplo, cuando un procesador de 8 bits debe sumar dos enteros de 16 bits, el procesador primero debe adicionar los 8 bits de orden inferior de cada número entero con la instrucción de adición, a continuación, 
		añadir los 8 bits de orden superior utilizando la instrucción de adición con acarreo que tiene en cuenta el bit de acarreo de la adición de orden inferior, en este caso un procesador de 8 bits requiere dos instrucciones para completar una sola operación, en donde un procesador de 16 bits necesita una sola instrucción para poder completarla. Históricamente, los microprocesadores de 4 bits fueron sustituidos por unos de 8 bits, luego de 16 bits y 32 bits, esta tendencia general llegó a su fin con la introducción de procesadores de 64 bits, lo que ha sido un estándar en la computación de propósito general durante la última década.
		</p>
		<p align="left">
		Paralelismo a nivel instruccion
		Los procesadores modernos tienen ''pipeline'' de instrucciones de varias etapas. Cada etapa en el pipeline corresponde a una acción diferente que el procesador realiza en la instrucción correspondiente a la etapa; un procesador con un pipeline de N etapas puede tener hasta n instrucciones diferentes en diferentes etapas de finalización. El ejemplo canónico de un procesador segmentado es un procesador RISC, con cinco etapas: pedir instrucción, decodificar, ejecutar, acceso a la memoria y escritura. El procesador Pentium 4 tenía un pipeline de 35 etapas.
		</p>
		<p align="left">
		El paralelismo de datos es el paralelismo inherente en programas con ciclos, que se centra en la distribución de los datos entre los diferentes nodos computacionales que deben tratarse en paralelo. "La paralelización de ciclos conduce a menudo a secuencias similares de operaciones —no necesariamente idénticas— o funciones que se realizan en los elementos de una gran estructura de datos". Muchas de las aplicaciones científicas y de ingeniería muestran paralelismo de datos. Una dependencia de terminación de ciclo es la dependencia de una iteración de un ciclo en la salida de una o más iteraciones anteriores. Las dependencias de terminación de ciclo evitan la paralelización de ciclos.
		</p>
		<p align="center">4.2.1 Clasificación</p>
		<p align="left">
		Las computadoras paralelas se pueden clasificar de acuerdo con el nivel en el que el hardware soporta paralelismo. Esta clasificación es análoga a la distancia entre los nodos básicos de cómputo. Estos no son excluyentes entre sí, por ejemplo, los grupos de multiprocesadores simétricos son relativamente comunes.
		<p align="left"> Computación multinúcleo: un procesador multinúcleo es un procesador que incluye múltiples unidades de ejecución (núcleos) en el mismo chip. Un procesador multinúcleo puede ejecutar múltiples instrucciones por ciclo de secuencias de instrucciones múltiples.</p>
		<p align="left"> Multiprocesamiento simétrico: un multiprocesador simétrico (SMP) es un sistema computacional con múltiples procesadores idénticos que comparten memoria y se conectan a través de un bus. La contención del bus previene el escalado de esta arquitectura.</p>
		<p align="left"> Computación en clúster: un clúster es un grupo de ordenadores débilmente acoplados que trabajan en estrecha colaboración, de modo que en algunos aspectos pueden considerarse como un solo equipo.</p>
		<p align="left"> Procesamiento paralelo masivo: tienden a ser más grandes que los clústeres, con «mucho más» de 100 procesadores. En un MPP, cada CPU tiene su propia memoria y una copia del sistema operativo y la aplicación.
		<p align="left"> Computación distribuida: la computación distribuida es la forma más distribuida de la computación paralela. Se hace uso de ordenadores que se comunican a través de la Internet para trabajar en un problema dado.
		<p align="left"> Computadoras paralelas especializadas: dentro de la computación paralela, existen dispositivos paralelos especializados que generan interés. Aunque no son específicos para un dominio, tienden a ser aplicables sólo a unas pocas clases de problemas paralelos.</p>
		<p align="left"> Cómputo reconfigurable con arreglos de compuertas programables: el cómputo reconfigurable es el uso de un arreglo de compuertas programables (FPGA) como coprocesador de un ordenador de propósito general.</p>
		<p align="left"> Cómputo de propósito general en unidades de procesamiento gráfico (GPGPU): es una tendencia relativamente reciente en la investigación de ingeniería informática. Los GPUs son co-procesadores que han sido fuertemente optimizados para procesamiento de gráficos por computadora.</p>
		<p align="left"> Circuitos integrados de aplicación específica: debido a que un ASIC (por definición) es específico para una aplicación dada, puede ser completamente optimizado para esa aplicación. Como resultado, para una aplicación dada, un ASIC tiende a superar a un ordenador de propósito general.</p>
		<p align="left"> Procesadores vectoriales: pueden ejecutar la misma instrucción en grandes conjuntos de datos. Tienen operaciones de alto nivel que trabajan sobre arreglos lineales de números o vectores.
		</p>
		<p align="center">4.2.3 Organización de direcciones de memoria</p>
		<p align="left">
		La memoria principal en un ordenador en paralelo puede ser compartida —compartida entre todos los elementos de procesamiento en un único espacio de direcciones—, o distribuida —cada elemento de procesamiento tiene su propio espacio local de direcciones—. El término memoria distribuida se refiere al hecho de que la memoria se distribuye lógicamente, pero a menudo implica que también se distribuyen físicamente. La memoria distribuida- compartida y la virtualización de memoria combinan los dos enfoques, donde el procesador tiene su propia memoria local y permite acceso a la memoria de los procesadores que no son locales. Los accesos a la memoria local suelen ser más rápidos que los accesos a memoria no local. 
		Las arquitecturas de ordenador en las que cada elemento de la memoria principal se puede acceder con igual latencia y ancho de banda son conocidas como arquitecturas de acceso uniforme a memoria (UMA). Típicamente, sólo se puede lograr con un sistema de memoria compartida, donde la memoria no está distribuida físicamente. Un sistema que no tiene esta propiedad se conoce como arquitectura de acceso a memoria no uniforme (NUMA). Los sistemas de memoria distribuidos tienen acceso no uniforme a la memoria.
		</p>
		<p align="center">4.3 Sistemas de memoria en multiprocesadores</p>
		<p align="left"> Todos los procesadores acceden a una memoria común.</p>
		<p align="left"> La comunicación entre procesadores se hace a través de la memoria.</p>
		<p align="left"> Se necesitan primitivas de sincronismo para asegurar el intercambio de datos.</p>
		<p align="center">4.3.1 Redes de interconexion dinámica</p>
		<p align="center">4.3.2 Medio compartido</p>
		<p align="left">
		Medio compartido.
		Conexión por bus compartido
 		Es la organización más común en los computadores personales y servidores.
		El bus consta de líneas de dirección, datos y control para implementar:
		<p align="left"> El protocolo de transferencias de datos con la memoria.</p>
		<p align="left"> El arbitraje del acceso al bus cuando más de un procesador compite por utilizarlo.</p>
		Los procesadores utilizan cachés locales para:
		<p align="left"> Reducir el tiempo medio de acceso a memoria, como en un monoprocesador.</p>
		<p align="left"> Disminuir la utilización del bus compartido.</p>
		</p>
		<p align="center">4.3.3 Conmutadas</p>
		<p align="left">
		Conexión por conmutadores crossbar.
		Cada procesador (Pi) y cada módulo de memoria (Mi) tienen su propio bus. Existe un conmutador (S) en los puntos de intersección que permite conectar un bus de memoria con un bus de procesador. Para evitar conflictos cuando más de un procesador pretende acceder al mismo módulo de memoria se establece un orden de prioridad. Se trata de una red sin bloqueo con una conectividad completa pero de alta complejidad.
		</p>
		<p align="center">4.4 Sistemas de memoria de multicomputadoras</p>
		Cada procesador tiene su propia memoria y la comunicación se realiza por intercambio explícito de mensajes a través de una red. Ventajas</p>
		<p align="left"> El número de nodos puede ir desde algunas decenas hasta varios miles (o más).</p>
		<p align="left"> La arquitectura de paso de mensajes tiene ventajas sobre la de memoria compartida cuando el número de procesadores es grande.</p>
		<p align="left"> El número de canales físicos entre nodos suele oscilar entre cuatro y ocho.</p>
		<p align="left"> Esta arquitectura es directamente escalable y presenta un bajo coste para sistemas grandes.</p>
		<p align="left"> Un problema se especifica como un conjunto de procesos que se comunican entre sí y que se hacen corresponder sobre la estructura física de procesadores.</p>
		Desventajas
		<p align="left"> Se necesitan técnicas de sincronización para acceder a las variables compartidas.</p>
		<p align="left"> La contención en la memoria puede reducir significativamente la velocidad.</p>
		<p align="left"> No son fácilmente escalables a un gran número de procesadores.</p>
		<p align="center">4.4.1 Red de interconexión estatica</p>
		<p align="left">
		Los multicomputadores utilizan redes estáticas con enlaces directos entre nodos. Cuando un nodo recibe un mensaje lo procesa si viene dirigido a dicho nodo. Si el mensaje no va dirigido al nodo receptor lo reenvía a otro por alguno de sus enlaces de salida siguiendo un protocolo de encaminamiento.
		Propiedades más significativas
		</p>
		<p align="left"> Topología de la red: determina el patrón de interconexión entre nodos.</p>
		<p align="left"> Diámetro de la red: distancia máxima de los caminos más cortos entre dos nodos de la red.</p>
		<p align="left"> Latencia: retardo de tiempo en el peor caso para un mensaje transferido a través de la red.</p>
		<p align="left"> Ancho de banda: Transferencia máxima de datos en Mbytes/segundo.</p>
		<p align="left"> Escalabilidad: posibilidad de expansión modular de la red.</p>
		<p align="left"> Grado de un nodo: número de enlaces o canales que inciden en el nodo.</p>
		<p align="left"> Algoritmo de encaminamiento: determina el camino que debe seguir un mensaje desde el nodo emisor al nodo receptor.</p>
		<p align="center">4.4.1 Red de interconexión estatica</p>
		Por numerosos motivos, el procesamiento distribuido se ha convertido en un área de gran importancia e interés dentro de la ciencia de la computación, produciendo profundas transformaciones en las líneas de investigación y desarrollo. Interesa realizar investigación en la especificación, transformación, optimización y evaluación de algoritmos distribuidos y paralelos. Esto incluye el diseño y desarrollo de sistemas paralelos, la transformación de algoritmos secuenciales en paralelos, y las métricas de evaluación de performance sobre distintas plataformas de soporte (hardware y software). Más allá de las mejoras constantes en las arquitecturas físicas de soporte, uno de los mayores desafíos se centra en cómo aprovechar al máximo la potencia de las mismas.
		Líneas de investigación y desarrollo
		<p align="left"> Paralelización de algoritmos secuenciales. Diseño y optimización de algoritmos.</p>
		<p align="left"> Arquitecturas multicore y multithreading en multicore.</p>
		<p align="left"> Modelos de representación y predicción de performance de algoritmos paralelos.</p>
		<p align="left"> Mapping y scheduling de aplicaciones paralelas sobre distintas arquitecturas multiprocesador.</p>
		<p align="left"> Métricas del paralelismo. Speedup, eficiencia, rendimiento, granularidad, superlinealidad.</p>
		<p align="left"> Balance de carga estático y dinámico. Técnicas de balanceo de carga.</p>
		<p align="left"> Análisis de los problemas de migración y asignación óptima de procesos y datos a procesadores.</p>
		<p align="left"> Patrones de diseño de algoritmos paralelos.</p>
		<p align="left"> Escalabilidad de algoritmos paralelos en arquitecturas multiprocesador distribuidas.</p>
		<p align="left"> Implementación de soluciones sobre diferentes modelos de arquitectura homogéneas y heterogéneas.</p>
		<p align="left"> Laboratorios remotos para el acceso transparente a recursos de cómputo paralelo.</p>
	</div>
</body>
</html>